{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Line = namedtuple('Line', 'race_type race_location race_day race_time rank bib name country start_behind prone1 prone2 stand1 stand2 err_total result_time cup_points pdf_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2001-2019 seasons\n",
    "\n",
    "locations = {'AUT' : ['Hochfilzen'], \n",
    "             'SLO' : ['Pokljuka'], \n",
    "             'SVK' : ['Brezno-Osrblie'],\n",
    "             'GER' : ['Oberhof', 'Ruhpolding', 'Chiemgau Arena', 'Biathlon Stadion Am Grenzadler'],\n",
    "             'ITA' : ['Antholz-Anterselva', 'Antholz - Anterselva', 'Cesana San Sicario', 'Torino', 'Antholz Obertal'],\n",
    "             'USA' : ['Soldier Hollow', 'Verizon Sports Complex', 'Maine Winter Sports Center', 'Presque Isle', '10TH MOUNTAIN SKI CENTER'],\n",
    "             'SWE' : ['Oestersund', 'Ã–stersund'],\n",
    "             'FIN' : ['Lahti', 'Kontiolahti', 'BIATHLON STADIUM KONTIOLAHTI', 'KONTIOLAHTI'],\n",
    "             'NOR' : ['Holmenkollen', 'Beitostolen', 'Trondheim'],\n",
    "             'RUS' : ['Khanty-Mansiysk', 'Nordic Ski Centre', 'SOCHI', 'Tyumen', 'Laura Cross-Country Ski', \n",
    "                      'Khanty Mansiysk', 'A.V. Filipenko Winter Sports Center', 'Nordic Sport Complex'],\n",
    "             'KOR' : ['PyeongChang', 'Alpensia Biathlon Center', 'Alpensia Biathlon Centre'],\n",
    "             'CAN' : ['Whistler', 'Vancouver', 'Canmore', 'Whistler Olympic Park'],\n",
    "             'CZE' : ['Nove Mesto'],\n",
    "             'FRA' : ['Annecy-Le Grand Bornand', 'Annecy']\n",
    "            }\n",
    "\n",
    "r_types = ['INDIVIDUAL', 'SPRINT', 'Pursuit', 'MASS START', 'RELAY', 'MIXED RELAY', 'SINGLE MIXED']\n",
    "\n",
    "loc_to_date = {'Oberhof' : ['2002-01-20', '2005-01-09'], \n",
    "               'Antholz-Anterselva' : ['2002-01-27', '2006-01-20', '2006-01-21', '2008-01-19', '2009-01-24', '2010-01-24'], \n",
    "               'Lahti' : ['2002-03-17', '2007-03-04'],\n",
    "               'Holmenkollen' : ['2002-03-23', '2006-03-25', '2010-03-20'],\n",
    "               'Brezno-Osrblie' : ['2002-12-22', '2003-12-21', '2005-12-18'],\n",
    "               'Ruhpolding' : ['2003-01-19', '2004-01-18', '2009-01-18', '2011-01-16'],\n",
    "               'Khanty-Mansiysk' : ['2003-03-16', '2007-03-17', '2011-03-06'],\n",
    "               'Oestersund' : ['2005-11-27', '2006-12-03', '2008-02-10'],\n",
    "               'Pokljuka' : ['2006-03-11', '2009-12-20'],\n",
    "               'Kontiolahti' : ['2006-03-18', '2010-03-14', '2015-03-08'],\n",
    "               'Hochfilzen' : ['2006-12-09', '2008-12-13', '2010-12-11', '2010-12-12'],\n",
    "               'Trondheim' : ['2009-03-21'],\n",
    "               'Presque Isle' : ['2011-02-06']\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a regex string that refers to r_types list\n",
    "race_types_regex_str = ''\n",
    "for i in r_types:\n",
    "    race_types_regex_str += '.*{}|'.format(i)\n",
    "\n",
    "race_type_re = re.compile(r'{}'.format(race_types_regex_str), re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all locations in one list\n",
    "loc_list = []\n",
    "for v in locations.values():\n",
    "    for i in v:\n",
    "        loc_list.append(i.lower())\n",
    "        loc_list.append(i)\n",
    "        loc_list.append(i.upper())\n",
    "        \n",
    "# making regex to match locations\n",
    "locations_regex_str = ''\n",
    "for i in loc_list:\n",
    "    locations_regex_str += '{}|'.format(i)\n",
    "\n",
    "location_re = re.compile(r'{}'.format(locations_regex_str[:-1]), re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating regex fo matching the date of the race\n",
    "\n",
    "race_day_re = re.compile(r'(?<=\\w\\w\\w\\s)\\d{1,2}\\s\\w\\w\\w\\s\\d{4}|(?<=\\w\\w\\w\\s\\s)\\d{1,2}\\s\\w\\w\\w\\s\\d{4}')\n",
    "\n",
    "# creating the regex to match the start tome of the race\n",
    "\n",
    "race_time_re = re.compile(r'(?<=START TIME:|Start Time:|START TIME |start time |Start Time )(\\s*)(\\d\\d:\\d\\d)|(?<=DEBUT)(\\s*)(\\d\\d:\\d\\d)')\n",
    "\n",
    "# creating regex to match player performance\n",
    "performance_re = re.compile((r\"(?P<rank>(?<![a-zA-Z]\\s)(?<=[=])?\\d{1,2}(?=\\s\\d{1,2}))?\\s?\"\n",
    "                             \"(?(rank)(?P<bib1>(?<![a-zA-Z]\\s)\\d{1,2}y?r?)|(?P<bib2>(?<![a-zA-Z]\\s)\\A\\d{1,2}y?r?))\\s?(?=\\s?[a-z\\u0080-\\uFFFFA-Z.\\')(-]{2})\"\n",
    "                             \"(?P<name>[a-z\\u0080-\\uFFFFA-Z\\s.\\')(-]*\\s[\\u0080-\\uFFFFa-zA-Z\\s.\\')(-:]*(?=\\s[A-Z]{3}))\\s\"\n",
    "                             \"(?P<country>[A-Z]{3}(?=\\s))\\s*\"\n",
    "                             \"(?P<start_behind>\\d{1,2}:\\d{2})?\\s?\"\n",
    "                             \"(?P<prone1>[0,1,2,3,4,5]{1})?\\s?\"\n",
    "                             \"(?P<prone2>[0,1,2,3,4,5]{1})?\\s?\"\n",
    "                             \"(?P<stand1>[0,1,2,3,4,5]{1})?\\s?\"\n",
    "                             \"(?P<stand2>[0,1,2,3,4,5]{1})?\\s?\"\n",
    "                             \"(?P<err_total>\\d{1,2})?\\s*\"\n",
    "                             \"(?P<result_time>[+]?\\d{1,2}:{0,1}\\d{0,2}.\\d{1,2})?\\s?\"\n",
    "                             \"(?P<cup_points>(?<=[.]\\d\\s)\\d{1,3})?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta re\n",
    "# performance_re = re.compile(r\"(?P<rank>(?<![a-zA-Z]\\s)(?<=[=])?\\d{1,2}(?=\\s\\d{1,2}))?\\s?(?(rank)(?P<bib1>(?<![a-zA-Z]\\s)\\d{1,2}y?r?)|(?P<bib2>(?<![a-zA-Z]\\s)\\A\\d{1,2}y?r?))\\s?(?=\\s?[a-z\\u0080-\\uFFFFA-Z.\\')(-]{2})(?P<name>[a-z\\u0080-\\uFFFFA-Z\\s.\\')(-]*\\s[\\u0080-\\uFFFFa-zA-Z\\s.\\')(-:]*(?=\\s[A-Z]{3}))\\s(?P<country>[A-Z]{3}(?=\\s))\\s*(?P<start_behind>\\d{1,2}:\\d{2})?\\s?(?P<prone1>[0,1,2,3,4,5]{1})?\\s?(?P<prone2>[0,1,2,3,4,5]{1})?\\s?(?P<stand1>[0,1,2,3,4,5]{1})?\\s?(?P<stand2>[0,1,2,3,4,5]{1})?\\s?(?P<err_total>\\d{1,2})?\\s*(?P<result_time>[+]?\\d{1,2}:{0,1}\\d{0,2}.\\d{1,2})?\\s?(?P<cup_points>(?<=[.]\\d\\s)\\d{1,3})?\")\n",
    "# performance_re = re.compile(r\"(?P<rank>(?<![a-zA-Z]\\s)(?<=[=])?\\d{1,2}(?=\\s\\d{1,2}))?\\s?(?(rank)(?P<bib1>(?<![a-zA-Z]\\s)\\d{1,2}y?r?)|(?P<bib2>(?<![a-zA-Z]\\s)\\A\\d{1,2}y?r?))\\s?(?=\\s?[a-z\\u0080-\\uFFFFA-Z.\\')(-]{2})(?P<name>[a-z\\u0080-\\uFFFFA-Z\\s.\\')(-]*\\s[\\u0080-\\uFFFFa-zA-Z\\s.\\')(-:]*(?=\\s?[A-Z]{3}))\\s?(?P<country>[A-Z]{3}(?=\\s))\\s*(?P<start_behind>\\d{1,2}:\\d{2})?\\s?(?P<prone1>[0,1,2,3,4,5]{1})?\\s?(?P<prone2>[0,1,2,3,4,5]{1})?\\s?(?P<stand1>[0,1,2,3,4,5]{1})?\\s?(?P<stand2>[0,1,2,3,4,5]{1})?\\s?(?P<err_total>\\d{1,2})?\\s*(?P<result_time>[+]?\\d{1,2}:{0,1}\\d{0,2}.\\d{1,2})?\\s?(?P<cup_points>(?<=[.]\\d\\s)\\d{1,3})?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that later will be applied to series object to map venues/cities to countries\n",
    "def loc_to_country(x):\n",
    "    for country, v_list in locations.items():\n",
    "        for v in v_list:\n",
    "            if x == v.lower():\n",
    "                x = country\n",
    "    return x\n",
    "\n",
    "# function that later will be applied to dataframe to remove duplicate names\n",
    "with open('unique_names.txt') as f: #file containing dictionary with unique name as keys and duplicate keys as values\n",
    "    unique_names_dict = eval(f.read())\n",
    "def name_lookups(x):\n",
    "    for or_name, dup_names in unique_names_dict.items():\n",
    "        for dup_name in dup_names:\n",
    "            if x == dup_name:\n",
    "                x = or_name\n",
    "    return x\n",
    "\n",
    "# func that later will be applied to 'name' column of df_startlist dataframe to cheaply remove bibs from names\n",
    "def bib_remover(row):\n",
    "    if row[:3] == 'yr ':\n",
    "        return row[3:]\n",
    "    if row[:2] == 'y ' or row[:2] == 'r ':\n",
    "        return row[2:]\n",
    "    else:\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to print pdf line-by-line\n",
    "def print_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        pages = pdf.pages\n",
    "        text_to_print = ''\n",
    "        for page in pages:\n",
    "            text_to_print += page.extract_text() + '\\n'\n",
    "    return text_to_print.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        pages = pdf.pages\n",
    "        pdf_text = ''\n",
    "        for page in pages:\n",
    "            pdf_text += page.extract_text() + '\\n'\n",
    "   \n",
    "    ntuples_lines = []\n",
    "    race_type_match = None\n",
    "    race_location_match = None\n",
    "    race_day_match = None\n",
    "    race_time_match = None\n",
    "\n",
    "    skipper = 0\n",
    "    \n",
    "    for l in pdf_text.split('\\n'): # for skipping the rows that go after 'revised'\n",
    "        if skipper == 1:\n",
    "            if not race_location_match:\n",
    "                race_location = location_re.search(l)\n",
    "                if race_location:\n",
    "                    race_location_match = race_location.group(0)\n",
    "            skipper = 0\n",
    "            continue\n",
    "        if l == 'REVISED':\n",
    "            skipper += 1\n",
    "        \n",
    "        if l != '' and l[0] == '=': # to fix inconsistency where in some pdf equeal ranks are written as '=1'\n",
    "            l = l[1:]\n",
    "        if l != '' and l[0:3] == 'FF ': # to fix inconsistency where in some pdf there is photofinish marked as FF\n",
    "            l = l[3:]\n",
    "        if 'WeronikaPOL' in l:\n",
    "            l = l.replace('WeronikaPOL', 'Weronika POL') # wierd bug with country 'glued' to name, failed to change my regex without ruining everything else\n",
    "        if 'WeronikPaOL' in l:\n",
    "            l = l.replace('WeronikPaOL', 'Weronika POL')\n",
    "        if ' yr ' in l:\n",
    "            l = l.replace(' yr ', ' ')\n",
    "        if ' r ' in l:\n",
    "            l = l.replace(' r ', ' ')\n",
    "        if ' y ' in l:\n",
    "            l = l.replace(' y ', ' ')\n",
    "        if ' b ' in l:\n",
    "            l = l.replace(' b ', ' ')\n",
    "        \n",
    "        if not race_type_match:\n",
    "            race_type = race_type_re.search(l)\n",
    "            if race_type.group(0) != '':\n",
    "                race_type_match = race_type.group(0)\n",
    "        if not race_location_match:\n",
    "            race_location = location_re.search(l)\n",
    "            if race_location:\n",
    "                race_location_match = race_location.group(0)\n",
    "        if not race_day_match:\n",
    "            race_day = race_day_re.search(l)\n",
    "            if race_day:\n",
    "                race_day_match = race_day.group(0)\n",
    "        if not race_time_match:\n",
    "            race_time = race_time_re.search(l)\n",
    "            if race_time:\n",
    "                race_time_match = race_time.group(2) if race_time.group(2) else race_time.group(4)\n",
    "\n",
    "        performance = performance_re.search(l)\n",
    "        rank=bib=name=country=start_behind=prone1=prone2=stand1=stand2=err_total=result_time=cup_points = None\n",
    "        if performance:\n",
    "            rank = performance.group('rank') if performance.group('rank') else 0\n",
    "            bib = performance.group('bib1') if performance.group('bib1') else performance.group('bib2')\n",
    "            name = performance.group('name')\n",
    "            country = performance.group('country')\n",
    "            start_behind = performance.group('start_behind')\n",
    "            prone1 = performance.group('prone1') if performance.group('prone1') else np.nan\n",
    "            prone2 = performance.group('prone2') if performance.group('prone2') else np.nan\n",
    "            stand1 = performance.group('stand1') if performance.group('stand1') else np.nan\n",
    "            stand2 = performance.group('stand2') if performance.group('stand2') else np.nan\n",
    "            err_total = performance.group('err_total') if performance.group('err_total') else np.nan\n",
    "            result_time = performance.group('result_time') if performance.group('result_time') else np.nan\n",
    "            cup_points = performance.group('cup_points') if performance.group('cup_points') else np.nan\n",
    "        if name != None:\n",
    "            ntuples_lines.append(Line(race_type_match, race_location_match, race_day_match, race_time_match, \n",
    "                                      rank, bib, name, country, start_behind, prone1, prone2, stand1,\n",
    "                                      stand2, err_total, result_time, cup_points, pdf_path))\n",
    "        if 'time adjustment' in l.lower() or 'disqualified' in l.lower() or 'result cancellation' in l.lower():\n",
    "            break\n",
    "    return pd.DataFrame(ntuples_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this parse_dir\n",
    "\n",
    "def parse_dir(directory):\n",
    "    pdf_list = []\n",
    "    for foldername, _, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            if str(filename).endswith('.pdf'):\n",
    "                pdf_list.append(os.path.join(foldername, filename))\n",
    "    \n",
    "    counter = 0\n",
    "    df = None\n",
    "    for item in tqdm(pdf_list):\n",
    "        df_temp = parse_pdf(item)\n",
    "        df_temp['race_id'] = ('0000' + str(counter))[-4:] #for generating unique race_id's\n",
    "        if counter > 0:\n",
    "            df = pd.concat([df, df_temp], ignore_index=True)\n",
    "        else:\n",
    "            df = df_temp\n",
    "        counter += 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading function\n",
    "\n",
    "def load_data():\n",
    "    df_purst = parse_dir('race_data/pursuit/')\n",
    "    df_start = parse_dir('race_data/startlist_pursuit/')\n",
    "    \n",
    "    # fixing incorrectly parsed rows with wierd countries/month names\n",
    "    df_purst = df_purst.drop(df_purst[df_purst.country.isin(['JAN', 'FEB', 'MAR', 'APR', 'MAY', \n",
    "                                                             'JUN', 'SKI', 'END', 'JUL', 'AUG', 'ADR',\n",
    "                                                             'SEP', 'OCT', 'NOV', 'DEC', 'IBU', 'ECR'])].index)\n",
    "    df_start = df_start.drop(df_start[df_start.country.isin(['JAN', 'FEB', 'MAR', 'APR', 'MAY', \n",
    "                                                             'JUN', 'SKI', 'END', 'JUL', 'AUG', 'ADR',\n",
    "                                                             'SEP', 'OCT', 'NOV', 'DEC', 'IBU', 'ECR'])].index)  \n",
    "    df_purst.loc[df_purst['race_day'] == '14 MRZ 2010', 'race_day'] = '14 MAR 2010'\n",
    "    \n",
    "    # coverting race_day to datetime\n",
    "    df_purst['race_day'] = pd.to_datetime(df_purst['race_day'])\n",
    "    df_start['race_day'] = pd.to_datetime(df_start['race_day'])\n",
    "    \n",
    "    # Getting the race_days with missing race_locations into a list, matching with loc_to_date dict, filling misssing values\n",
    "    days_with_missing_locations_purst = [str(x)[:10] for x in \n",
    "                                         df_purst.loc[df_purst['race_location'].isnull()]['race_day'].value_counts().index]\n",
    "    for date in days_with_missing_locations_purst:\n",
    "        for venue, v_date in loc_to_date.items():\n",
    "            if date in v_date:\n",
    "                df_purst.loc[df_purst['race_day'] == date, 'race_location'] = venue\n",
    "    days_with_missing_locations_start = [str(x)[:10] for x in \n",
    "                                         df_start.loc[df_start['race_location'].isnull()]['race_day'].value_counts().index]\n",
    "    for date in days_with_missing_locations_start:\n",
    "        for venue, v_date in loc_to_date.items():\n",
    "            if date in v_date:\n",
    "                df_start.loc[df_start['race_day'] == date, 'race_location'] = venue\n",
    "    \n",
    "    # Making all locations lowercase for 'normalization'\n",
    "    df_purst['race_location'] = df_purst['race_location'].apply(lambda x: x.lower())\n",
    "    \n",
    "    # Creating gender column\n",
    "    df_purst['gender'] = df_purst['race_type'].apply(lambda x:'male' if '12.5' in x else 'female')\n",
    "    df_start['gender'] = df_start['race_type'].apply(lambda x:'male' if '12.5' in x else 'female')\n",
    "    \n",
    "    # mapping venue/city ('race_location') to corresponding country ('race_country')\n",
    "    df_purst['race_country'] = df_purst['race_location'].apply(loc_to_country)\n",
    "    \n",
    "    #filling missing start_behind based on values from df_start dataframe\n",
    "        #removing bib types from name column in startlist dataframe and from bib column in pursuit dataframe\n",
    "    df_purst['bib'] = df_purst['bib'].apply(lambda x: x.rstrip('yr'))\n",
    "    df_start['name'] = df_start['name'].apply(bib_remover)\n",
    "        #create unique key for each dataframe to update on...\n",
    "    df_purst['date_bib_ind'] = df_purst['race_day'].apply(lambda x: x.strftime('%Y-%m-%d')) +'-'+ df_purst['bib'] +'-'+ df_purst['gender']\n",
    "    df_start['date_bib_ind'] = df_start['race_day'].apply(lambda x: x.strftime('%Y-%m-%d')) +'-'+ df_start['bib'] +'-'+ df_start['gender']\n",
    "        #..then set index to created column\n",
    "    df_purst.set_index('date_bib_ind', inplace=True)\n",
    "    df_start.set_index('date_bib_ind', inplace=True)\n",
    "    df_purst.loc['2017-01-07-49-female', 'start_behind'] = '2:30' #single-case bug where name splits into 3 lines, decided to input manually\n",
    "        #update only nans in df_purst start_behind\n",
    "    df_purst.update(df_start['start_behind'], overwrite=False)\n",
    "    df_purst.reset_index(inplace=True)\n",
    "    df_purst.drop('date_bib_ind',axis=1, inplace=True)\n",
    "    \n",
    "    # removing duplicates from name column\n",
    "    df_purst['name'] = df_purst['name'].apply(name_lookups)\n",
    "    \n",
    "    return df_purst, df_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 294/294 [01:12<00:00,  4.06it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 105/105 [00:43<00:00,  2.40it/s]\n"
     ]
    }
   ],
   "source": [
    "df_pursuit, df_startlist = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_type</th>\n",
       "      <th>race_location</th>\n",
       "      <th>race_day</th>\n",
       "      <th>race_time</th>\n",
       "      <th>rank</th>\n",
       "      <th>bib</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>start_behind</th>\n",
       "      <th>prone1</th>\n",
       "      <th>prone2</th>\n",
       "      <th>stand1</th>\n",
       "      <th>stand2</th>\n",
       "      <th>err_total</th>\n",
       "      <th>result_time</th>\n",
       "      <th>cup_points</th>\n",
       "      <th>pdf_path</th>\n",
       "      <th>race_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>MEN 12.5 KM PURSUIT</td>\n",
       "      <td>khanty-mansiysk</td>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>18:30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SCHEMPP Simon</td>\n",
       "      <td>GER</td>\n",
       "      <td>0:01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>33:27.8</td>\n",
       "      <td>60</td>\n",
       "      <td>race_data/pursuit/BT_C73D_1.0 - 2020-08-13T195...</td>\n",
       "      <td>0000</td>\n",
       "      <td>male</td>\n",
       "      <td>RUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>MEN 12.5 KM PURSUIT</td>\n",
       "      <td>khanty-mansiysk</td>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>18:30</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>BOE Johannes Thingnes</td>\n",
       "      <td>NOR</td>\n",
       "      <td>1:02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>+8.5</td>\n",
       "      <td>54</td>\n",
       "      <td>race_data/pursuit/BT_C73D_1.0 - 2020-08-13T195...</td>\n",
       "      <td>0000</td>\n",
       "      <td>male</td>\n",
       "      <td>RUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>MEN 12.5 KM PURSUIT</td>\n",
       "      <td>khanty-mansiysk</td>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>18:30</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>LESSER Erik</td>\n",
       "      <td>GER</td>\n",
       "      <td>0:38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>+15.7</td>\n",
       "      <td>48</td>\n",
       "      <td>race_data/pursuit/BT_C73D_1.0 - 2020-08-13T195...</td>\n",
       "      <td>0000</td>\n",
       "      <td>male</td>\n",
       "      <td>RUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>MEN 12.5 KM PURSUIT</td>\n",
       "      <td>khanty-mansiysk</td>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>18:30</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>WEGER Benjamin</td>\n",
       "      <td>SUI</td>\n",
       "      <td>1:15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>+18.7</td>\n",
       "      <td>43</td>\n",
       "      <td>race_data/pursuit/BT_C73D_1.0 - 2020-08-13T195...</td>\n",
       "      <td>0000</td>\n",
       "      <td>male</td>\n",
       "      <td>RUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>MEN 12.5 KM PURSUIT</td>\n",
       "      <td>khanty-mansiysk</td>\n",
       "      <td>2016-03-19</td>\n",
       "      <td>18:30</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>DOLL Benedikt</td>\n",
       "      <td>GER</td>\n",
       "      <td>1:03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>+27.3</td>\n",
       "      <td>40</td>\n",
       "      <td>race_data/pursuit/BT_C73D_1.0 - 2020-08-13T195...</td>\n",
       "      <td>0000</td>\n",
       "      <td>male</td>\n",
       "      <td>RUS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             race_type    race_location   race_day race_time rank bib  \\\n",
       "0  MEN 12.5 KM PURSUIT  khanty-mansiysk 2016-03-19     18:30    1   2   \n",
       "1  MEN 12.5 KM PURSUIT  khanty-mansiysk 2016-03-19     18:30    2   7   \n",
       "2  MEN 12.5 KM PURSUIT  khanty-mansiysk 2016-03-19     18:30    3   5   \n",
       "3  MEN 12.5 KM PURSUIT  khanty-mansiysk 2016-03-19     18:30    4  11   \n",
       "4  MEN 12.5 KM PURSUIT  khanty-mansiysk 2016-03-19     18:30    5   8   \n",
       "\n",
       "                    name country start_behind prone1 prone2 stand1 stand2  \\\n",
       "0          SCHEMPP Simon     GER         0:01      1      1      0      1   \n",
       "1  BOE Johannes Thingnes     NOR         1:02      0      0      0      1   \n",
       "2            LESSER Erik     GER         0:38      0      0      1      1   \n",
       "3         WEGER Benjamin     SUI         1:15      0      0      0      0   \n",
       "4          DOLL Benedikt     GER         1:03      1      0      1      0   \n",
       "\n",
       "  err_total result_time cup_points  \\\n",
       "0         3     33:27.8         60   \n",
       "1         1        +8.5         54   \n",
       "2         2       +15.7         48   \n",
       "3         0       +18.7         43   \n",
       "4         2       +27.3         40   \n",
       "\n",
       "                                            pdf_path race_id gender  \\\n",
       "0  race_data/pursuit/BT_C73D_1.0 - 2020-08-13T195...    0000   male   \n",
       "1  race_data/pursuit/BT_C73D_1.0 - 2020-08-13T195...    0000   male   \n",
       "2  race_data/pursuit/BT_C73D_1.0 - 2020-08-13T195...    0000   male   \n",
       "3  race_data/pursuit/BT_C73D_1.0 - 2020-08-13T195...    0000   male   \n",
       "4  race_data/pursuit/BT_C73D_1.0 - 2020-08-13T195...    0000   male   \n",
       "\n",
       "  race_country  \n",
       "0          RUS  \n",
       "1          RUS  \n",
       "2          RUS  \n",
       "3          RUS  \n",
       "4          RUS  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pursuit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values count for each column in df_purs: \n",
      "\n",
      "\n",
      "race_type: 0\n",
      "race_location: 0\n",
      "race_day: 0\n",
      "race_time: 0\n",
      "rank: 0\n",
      "bib: 0\n",
      "name: 0\n",
      "country: 0\n",
      "start_behind: 0\n",
      "prone1: 681\n",
      "prone2: 722\n",
      "stand1: 838\n",
      "stand2: 1060\n",
      "err_total: 1060\n",
      "result_time: 1158\n",
      "cup_points: 6798\n",
      "pdf_path: 0\n",
      "race_id: 0\n",
      "gender: 0\n",
      "race_country: 0\n"
     ]
    }
   ],
   "source": [
    "print('Missing values count for each column in df_purs: ')\n",
    "print('\\n')\n",
    "for col in df_pursuit.columns:\n",
    "    print(col+': '+str(df_pursuit[col].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pursuit.to_csv('pursuit_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
